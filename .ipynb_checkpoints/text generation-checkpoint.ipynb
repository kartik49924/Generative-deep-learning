{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
      "606208/600901 [==============================] - 2s 4us/step\n",
      "corpus length 600901\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "path=keras.utils.get_file('nietzche.txt',origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "text=open(path).read().lower()\n",
    "print(\"corpus length\",len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of characters are 59\n"
     ]
    }
   ],
   "source": [
    "sentences=[]\n",
    "next_char=[]\n",
    "maxlen=60\n",
    "step=3\n",
    "for i in range(0,len(text)-maxlen,step):\n",
    "    sentences.append(text[i:i+maxlen])\n",
    "    next_char.append(text[i+maxlen])\n",
    "char=sorted(list(set(text)))\n",
    "print(\"no of characters are\",len(char))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_index={x:char.index(x) for x in char}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.zeros((len(sentences),maxlen,len(char)),dtype=np.bool)\n",
    "y=np.zeros((len(sentences),len(char)),dtype=np.bool)\n",
    "for i,sentence in enumerate(sentences):\n",
    "    for j,character in enumerate(sentence):\n",
    "        x[i,j,char_index[character]]=1\n",
    "    y[i,char_index[next_char[i]]]=1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From F:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               96256     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 59)                7611      \n",
      "=================================================================\n",
      "Total params: 103,867\n",
      "Trainable params: 103,867\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(layers.LSTM(128,input_shape=(maxlen,len(char))))\n",
    "model.add(layers.Dense(len(char),activation='softmax'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='RMSprop',loss='categorical_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200281\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(prediction,p=1.0):\n",
    "    pred=np.asarray(prediction).astype('float64')\n",
    "    pred=np.log(pred)/p\n",
    "    pred=np.exp(pred)\n",
    "    pred=pred/np.sum(pred)\n",
    "    probab=np.random.multinomial(1,pred,1)\n",
    "    return np.argmax(probab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "model.fit(x,y,batch_size=128,epochs=1,verbose=0)\n",
    "#randomly generate text\n",
    "start_ind=random.randint(0,len(text)-maxlen-1)\n",
    "sample_txt=text[start_ind:start_ind+maxlen]\n",
    "print(\"The generated text___\",sample_txt)\n",
    "    \n",
    "for temperature in [.2,.5,1]:\n",
    "    for i  in range(400):\n",
    "        sample=np.zeros((1,maxlen,len(char)),dtype=bool)\n",
    "        for j,charac in enumerate(sample_txt):\n",
    "            sample[0,round(j),char_index[charac]]=1\n",
    "        preds=model.predict(sample)[0]\n",
    "        next_ch=sampling(preds,temperature)\n",
    "        sample_txt+=char[next_ch]\n",
    "        sample_txt=preds[1:]\n",
    "    print(\"Sample_text: temperature=\",temperature,'---')\n",
    "    print(sample_txt)\n",
    "        \n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
